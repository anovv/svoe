
apiVersion: kops.k8s.io/v1alpha2
kind: Cluster
metadata:
  name: {{.cluster_name.value}}
spec:
  api:
    dns: {}
  authorization:
    rbac: {}
  channel: stable
  cloudProvider: aws
  configBase: s3://{{.kops_s3_bucket_name.value}}/{{.cluster_name.value}}
  # Create one etcd member per AZ
  etcdClusters:
  - etcdMembers:
  {{range $i, $az := .azs.value}}
    - instanceGroup: master-{{.}}
      name: {{. | replace $.region.value "" }}
      encryptedVolume: true
#      volumeSize # TODO
  {{end}}
    name: main
    cpuRequest: 200m
    memoryRequest: 100Mi
  - etcdMembers:
  {{range $i, $az := .azs.value}}
    - instanceGroup: master-{{.}}
      name: {{. | replace $.region.value "" }}
      encryptedVolume: true
      # volumeSize # TODO
  {{end}}
    name: events
    cpuRequest: 100m
    memoryRequest: 100Mi
  - etcdMembers:
    {{range $i, $az := .azs.value}}
    - instanceGroup: master-{{.}}
      name: {{. | replace $.region.value "" }}
      encryptedVolume: true
      # volumeSize # TODO
    {{end}}
    name: cilium
    cpuRequest: 100m
    memoryRequest: 100Mi
    manager:
      env:
        - name: ETCD_AUTO_COMPACTION_MODE
          value: revision
        - name: ETCD_AUTO_COMPACTION_RETENTION
          value: "2500"
  iam:
    allowContainerRegistry: true
    legacy: false
  kubernetesVersion: 1.22.5
  masterPublicName: api.{{.cluster_name.value}}
  networkCIDR: {{.vpc_cidr_block.value}}
  kubeProxy:
    enabled: false # for cilium BPF
  networkID: {{.vpc_id.value}}
  kubelet:
    anonymousAuth: false
  networking:
    cilium:
      etcdManaged: true
      enableNodePort: true # BPF support
      enableEncryption: false
#      cpuRequest: "25m"
#      memoryRequest: "128Mi" TODO
  nonMasqueradeCIDR: {{.k8s_non_masquerade_cidr.value}}
  # TODO are these 0.0.0.0/0 needed?
  sshAccess:
  - 0.0.0.0/0
  kubernetesApiAccess:
  - 0.0.0.0/0
  subnets:
  # Public subnets, one per AZ
  {{range $i, $id := .public_subnets.value}}
  - id: {{.}}
    name: {{index $.azs.value $i}}
    type: Public
    zone: {{index $.azs.value $i}}
  {{end}}
  # Private subnets, one per AZ
  {{range $i, $id := .private_subnets.value}}
  - id: {{.}}
    name: {{index $.azs.value $i}}
    type: Private
    zone: {{index $.azs.value $i}}
    egress: {{index $.natgw_ids.value 0}}
  {{end}}
  topology:
    dns:
      type: Public
    masters: public
    nodes: public
---

# TODO optimize rootVolumeSize
# TODO for each InstanceGroup add extra security-groups to open necessary ports (e.g. Cilium etcd)
# Create one master per AZ
{{range .azs.value}}
apiVersion: kops.k8s.io/v1alpha2
kind: InstanceGroup
metadata:
  labels:
    kops.k8s.io/cluster: {{$.cluster_name.value}}
  name: master-{{.}}
spec:
  machineType: t3.medium
  maxSize: 1
  minSize: 1
  role: Master
  rootVolumeSize: 20
  rootVolumeType: gp2
  nodeLabels:
    kops.k8s.io/instancegroup: master-{{.}}
  subnets:
  - {{.}}
---
  {{end}}

apiVersion: kops/v1alpha2
kind: InstanceGroup
metadata:
  labels:
    kops.k8s.io/cluster: {{.cluster_name.value}}
  name: nodes-on-demand
spec:
  machineType: t3.small
  maxSize: 2
  minSize: 1
  role: Node
  rootVolumeSize: 20
  rootVolumeType: gp2
  nodeLabels:
    kops.k8s.io/instancegroup: nodes-on-demand
  subnets:
  {{range .azs.value}}
  - {{.}}
  {{end}}
---

# TODO set mixedInstancesPolicy
# TODO set warmPool
# TODO set maxPrice by instance type/dynamically
#apiVersion: kops/v1alpha2
#kind: InstanceGroup
#metadata:
#  labels:
#    kops.k8s.io/cluster: {{.cluster_name.value}}
#  name: nodes-spot
#spec:
#  machineType: t3.small
#  maxPrice: "0.0273" # on-demand price
#  maxSize: 2
#  minSize: 1
#  nodeLabels:
#    kops.k8s.io/instancegroup: nodes-spot
#  role: Node
#  rootVolumeSize: 20
#  rootVolumeType: gp2
#  subnets:
#  {{range .azs.value}}
#  - {{.}}
#  {{end}}